# 一字一句漏らさずテキスト化するための「プロンプト以外」の対策

画像→テキスト化で、プロンプトで「逐語的・要約禁止」と指定しても、解説などが要約や言い換えになってしまうことがあります。**プロンプトの修正以外**にできることを、自分の考えとインターネット調査を踏まえてまとめます。

---

## 1. なぜ「要約」や「抜け」が起きるか（整理）

### 1.1 自分の考え（構造的な要因）

- **LLMの性質**: モデルは「次トークン予測」で学習しているため、意味を保った言い換えや要約は得意だが、「一字一句コピーする」というタスクは相性が悪い。特に「解説」は「理解して説明する」ように働きやすい。
- **枚数・文量**: 複数枚・長文を一度に渡すと、どの部分をまだ書き出していないかの状態追跡が難しく、スキップ・重複・途中で打ち切りが起きやすい。
- **タスクの混在**: 「読み取る」「問題と解答に分類する」「Markdownで整形する」を一度にやると、「整形」の段階でつい要約や省略が入りやすい。

### 1.2 調査で得た知見

- **Verbatim Transcription**: LLMは「正確な逐語転写」が苦手で、長い出力では「どの要素をまだ出力したか」の追跡に失敗し、スキップ・重複・早期終了が起きる（State-tracking stress test 等の研究）。
- **抽出 vs 生成**: 「答えを生成する」のではなく「既存テキストスパンを抽出する」ようにすると hallucination が減り、一字一句に近づく（Verbatim RAG 等）。
- **OCR + AI の役割分担**: 文字列の取得は **OCR** に任せ、AI は **誤り訂正・構造化・フォーマット** だけに使うパイプラインが、文字レベル精度の面で有効（複数の実装例・ブログで言及）。
- **1ページずつ**: 長文を一度に渡さず、**1ページ（1画像）ずつ** 処理すると、truncate や skip を減らしやすい。

---

## 2. プロンプト以外でできること（推奨順）

### 2.1 【推奨】OCR ファースト＋AI は「構造化・誤字修正のみ」

**考え方**: 「一字一句」の文字列は **OCR が出力したテキストを正** とし、AI には「文言を変えずに Markdown 整形・問題/解答分類・OCR の明らかな誤認識だけ直す」を依頼する。

**手順例**:

1. **全ページを OCR でテキスト化する**
   - 既存ツール: `LearningTools/image-to-text-batch/image_to_text.py`
   - 例: `python image_to_text.py --folder "画像フォルダの絶対パス" --engine easyocr --output raw_ocr_chapter4.txt`
   - 日本語: `jpn+eng`（pytesseract）または `ja`（easyocr）で対応。
2. **OCR 結果を「正」として扱う**
   - 出力された生テキストは **1文字も変えず** 保存する（または版管理する）。
3. **AI に依頼する内容を限定する**
   - 「次の OCR 結果を、問題用・解答用の Markdown に整形してください。**文言は1文字も変えず**、見出し・コードブロック・選択肢の形式だけ整えてください。明らかな OCR の誤字（例: 0 と O の取り違え）だけ修正してください。」
   - これにより「生成」ではなく「整形＋最小限の訂正」になり、要約が入りにくい。

**メリット**: 文字列の出どころが OCR に固定され、AI は「書き換え」ではなく「並べ替え・マークアップ」に近い役割になる。  
**デメリット**: OCR の誤認識はそのまま残るため、難しいフォント・レイアウトでは誤字が増える。その分は照合・手動修正で補う。

---

### 2.2 1 ページ（1 画像）ずつ読み取り・出力する

**考え方**: プロンプトで「3〜8 枚程度」としている部分を **「1 枚ずつ」** に変え、**1 枚読んだらそのページ分のテキストを確定してから次** に進む。

- 各ターンで「今の画像は page_XXXX.png のみ。この画像のテキストを逐語で書き起こし、上記ファイルに追記してください」と明示する。
- 複数枚を一度に渡さないことで、状態追跡の失敗（スキップ・早期終了）を減らす。

**メリット**: 既存の「画像を AI が直接読む」やり方を維持しつつ、抜けを減らせる。  
**デメリット**: 枚数分だけやり取りが増える。

---

### 2.3 二段階に分ける（「転写」と「整形」を分離）

**考え方**: 「読み取り」と「整形」を **別タスク・別メッセージ** に分ける。

- **第 1 タスク（転写のみ）**
  - 「この画像に書かれているテキストを、要約・解説・言い換えを一切せず、**逐語で** 書き起こしてください。出力は本文だけにしてください。」
  - → 得られたテキストをそのまま確定する（コピペでファイルに保存など）。
- **第 2 タスク（整形のみ）**
  - 「次のテキストを、問題用（または解答用）の Markdown 形式に整形してください。**文言は1文字も変えず**、見出し・コードブロック・箇条書きの形式だけ整えてください。」

**メリット**: 「生成」と「転写」を分離できるため、解説部分が要約されにくい。  
**デメリット**: 手順が増え、画像を 2 回扱う場合がある。

---

### 2.4 照合の半自動化（抜け・差異の検出）

**考え方**: 出力の「抜け」や「違い」を、スクリプトや文字数で検出する。

- **文字数・行数の目安**
  - 元画像の枚数とおおよその文字数から、「この章は少なくとも ○○ 文字程度ある」という目安を決め、出力が極端に短ければ要確認とする。
- **OCR 結果との diff**
  - 2.1 のように OCR で生テキストを取っている場合、AI 整形結果と OCR 生テキストを diff し、「AI が省略した部分」を洗い出す。
- **照合レポートのテンプレ化**
  - 照合結果を「問番号・該当箇所・現状・あるべき内容」の形式で必ず書かせ、要修正リストを自動で作りやすくする。

**メリット**: 人の目だけに頼らず、抜けや不一致を機械的に疑える。  
**デメリット**: スクリプトやルールの整備が必要。

---

### 2.5 人間のスポットチェック（特に解説）

**考え方**: 特に「解説」は要約されやすいため、**数問をランダムに選び**、元画像と見比べて「原文のままか」を確認する。

- 例: 各章で問 1・問 15・問 30 など、数問だけ元画像と照合する。
- 要約や言い換えが多ければ、プロンプトの強化や 2.1〜2.3 の運用に切り替える判断材料になる。

---

## 3. 運用の組み合わせ例

| 目的 | 推奨の組み合わせ |
|------|-------------------|
| できるだけ一字一句に近づけたい | **2.1（OCR ファースト）** ＋ 2.4（diff/照合） |
| 今の「AI が画像を直接読む」を維持したい | **2.2（1 ページずつ）** ＋ **2.3（転写→整形の二段階）** |
| 手間を増やさず抜けを減らしたい | 2.4（文字数チェック・照合テンプレ） ＋ **2.5（スポットチェック）** |

---

## 4. 既存ツールの利用（OCR ファースト）

リポジトリ内の `LearningTools/image-to-text-batch/` で、画像フォルダを指定して一括 OCR できる。

- **EasyOCR**（Tesseract 不要）: `--engine easyocr`（日本語: `ja`）
- **Tesseract**: `--engine pytesseract`（日本語: `jpn+eng`。要 Tesseract 本体インストール）

出力は「1 ページ = 1 ブロック」でテキストが並ぶので、これを正として AI に「整形のみ・文言は変えない」と渡す運用が、**プロンプトだけに頼らない**現実的な方法です。

---

## 5. 参考（調査で参照した考え方）

- **Verbatim vs 要約**: 逐語転写は LLM の得意なタスクではなく、長文ではスキップ・重複が起きやすい。
- **Extract not generate**: 既存テキストの「抽出」に近づけると hallucination が減る。
- **OCR + LLM**: 文字列取得は OCR、構造化・訂正は LLM という役割分担で、文字レベル精度を上げる実例がある。
- **1 ページずつ**: 長文を分割して処理すると、truncate や skip を減らせる。

---

以上を、`PROMPT_IMAGE_TO_TEXT_AND_VERIFY.md` のプロンプトと**併用**すると、「全ページを 1 文字逃さず」に近づけやすくなります。プロンプト修正と合わせて、**OCR ファースト（2.1）** と **1 ページずつ＋二段階（2.2・2.3）** のいずれか（または両方）を試すのがおすすめです。
