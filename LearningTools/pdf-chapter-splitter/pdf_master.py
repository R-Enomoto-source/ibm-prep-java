"""
PDF Structure Master - PDFã‚’ç« ã”ã¨ã«åˆ†å‰²ã—ã€ç”»åƒåŒ–ã—ã¦ãƒ•ã‚©ãƒ«ãƒ€æ•´ç†ã™ã‚‹GUIã‚¢ãƒ—ãƒª
- ç›®æ¬¡ã‚ã‚Š: åŸ‹ã‚è¾¼ã¿ç›®æ¬¡ã‚’åˆ©ç”¨
- ç›®æ¬¡ãªã—: ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºè§£æã§ç« ã‚’è‡ªå‹•æ¤œå‡º
- å‡ºåŠ›: åˆ†å‰²PDF ã¾ãŸã¯ ç« ãƒ•ã‚©ãƒ«ãƒ€å†…ã®é€£ç•ªJPEGï¼ˆZIPï¼‰
èµ·å‹•: streamlit run pdf_master.py
"""
import streamlit as st
import fitz  # PyMuPDF
import io
import zipfile
import tempfile
import os
import shutil
import re
import platform
import subprocess
from dataclasses import dataclass
from pathlib import Path
from typing import List


def notify_ocr_complete():
    """OCRå®Œäº†æ™‚ã«é€šçŸ¥ã‚’å‡ºã™ï¼ˆãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ãƒ»éŸ³ï¼‰"""
    # ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—é€šçŸ¥ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶éè¡¨ç¤ºã§ã‚‚ç”»é¢ corner ã«è¡¨ç¤ºï¼‰
    try:
        from plyer import notification
        notification.notify(
            title="PDF Structure Master",
            message="OCRãŒå®Œäº†ã—ã¾ã—ãŸã€‚",
            app_name="PDF Structure Master",
            timeout=10,
        )
    except Exception:
        pass
    # ã‚·ã‚¹ãƒ†ãƒ éŸ³ã§è£œè¶³
    try:
        if platform.system() == "Windows":
            import winsound
            winsound.MessageBeep(winsound.MB_OK)
        elif platform.system() == "Darwin":
            subprocess.Popen(["afplay", "/System/Library/Sounds/Glass.aiff"], stderr=subprocess.DEVNULL)
    except Exception:
        pass

try:
    import ocrmypdf
    OCR_AVAILABLE = shutil.which("tesseract") is not None
except (ImportError, AttributeError):
    OCR_AVAILABLE = False


# --- ãƒ‡ãƒ¼ã‚¿æ§‹é€  ---
@dataclass
class ChapterInfo:
    title: str
    page_num: int
    level: int
    source: str
    selected: bool = True


# ã•ã¾ã–ã¾ãªæ›¸ç±ã§ä½¿ã‚ã‚Œã‚„ã™ã„ã€Œç« ã‚¿ã‚¤ãƒˆãƒ«ã€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
CHAPTER_PATTERN_GROUPS = [
    {
        "id": "ja_chapter",
        "label": "æ—¥æœ¬èª: ç¬¬1ç«  / 1ç«  / ç¬¬ä¸€ç« ",
        "patterns": [
            re.compile(r"ç¬¬?\s*[0-9ï¼-ï¼™ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒâ… â…¡â…¢â…£â…¤â…¥â…¦â…§â…¨â…©]+\s*ç« "),
            re.compile(r"[0-9ï¼-ï¼™ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\s*ç« "),
        ],
    },
    {
        "id": "ja_part",
        "label": "æ—¥æœ¬èª: ç¬¬1éƒ¨ / ç·¨ / è¬› / å›",
        "patterns": [
            re.compile(r"ç¬¬?\s*[0-9ï¼-ï¼™ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\s*(éƒ¨|ç·¨|è¬›|å›)"),
        ],
    },
    {
        "id": "en_chapter",
        "label": "è‹±èª: Chapter / CHAPTER / Chap.",
        "patterns": [
            re.compile(r"\bchapter\s+[0-9ivxlcdm]+\b", re.IGNORECASE),
            re.compile(r"\bchap\.\s*[0-9ivxlcdm]+\b", re.IGNORECASE),
        ],
    },
    {
        "id": "en_part_lesson",
        "label": "è‹±èª: Part / Lesson",
        "patterns": [
            re.compile(r"\bpart\s+[0-9ivxlcdm]+\b", re.IGNORECASE),
            re.compile(r"\blesson\s+[0-9ivxlcdm]+\b", re.IGNORECASE),
        ],
    },
    {
        "id": "eu_chapter",
        "label": "ãã®ä»–: Kapitel / Chapitre / CapÃ­tulo / Capitolo / Ğ“Ğ»Ğ°Ğ²Ğ° ãªã©",
        "patterns": [
            re.compile(
                r"\b(kapitel|chapitre|cap[iÃ­]tulo|capitolo|capitulo|glava|Ğ³Ğ»Ğ°Ğ²Ğ°)\s+[0-9ivxlcdmä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+\b",
                re.IGNORECASE,
            ),
        ],
    },
]

# ã™ã¹ã¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å¹³å¦åŒ–ã—ãŸãƒªã‚¹ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”¨ï¼‰
CHAPTER_TITLE_REGEXES = [p for g in CHAPTER_PATTERN_GROUPS for p in g["patterns"]]

# ç›®æ¬¡è¡Œã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆç« ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŠ ãˆã€ã€Œ1. ã¯ã˜ã‚ã«ã€ã€Œ1) ã¯ã˜ã‚ã«ã€ãªã©ã«ã‚‚å¯¾å¿œï¼‰
TOC_ENTRY_PATTERNS = [
    re.compile(r"^\d+[\.\)]\s"),  # "1. " or "1) "
    re.compile(r"^\d+\s+[^\d]"),  # "1 ã¯ã˜ã‚ã«" (æ•°å­—+ã‚¹ãƒšãƒ¼ã‚¹+éæ•°å­—)
] + CHAPTER_TITLE_REGEXES


def suggest_chapter_pattern_ids(chapters: List[ChapterInfo]) -> List[str]:
    """
    OCR ãªã©ã§æ¤œå‡ºã—ãŸè¦‹å‡ºã—ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã€
    ã©ã®ç« ã‚¿ã‚¤ãƒˆãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå®Ÿéš›ã«ä½¿ã‚ã‚Œã¦ã„ãã†ã‹ã‚’æ¨å®šã™ã‚‹ã€‚
    """
    if not chapters:
        return [g["id"] for g in CHAPTER_PATTERN_GROUPS]

    used_ids = set()
    for ch in chapters:
        title = (ch.title or "").strip()
        if not title:
            continue
        for g in CHAPTER_PATTERN_GROUPS:
            if any(pat.search(title) for pat in g["patterns"]):
                used_ids.add(g["id"])
    if not used_ids:
        return [g["id"] for g in CHAPTER_PATTERN_GROUPS]
    return sorted(used_ids)


# --- ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ ---
class PDFProcessor:
    def __init__(self, file_stream, filename):
        self.file_bytes = file_stream.read()
        self.filename = filename
        self.book_title = os.path.splitext(filename)[0]
        self.doc = fitz.open(stream=self.file_bytes, filetype="pdf")

    def run_ocr(self, language='jpn+eng') -> bool:
        if not OCR_AVAILABLE:
            return False
        with tempfile.TemporaryDirectory() as temp_dir:
            input_path = os.path.join(temp_dir, "input.pdf")
            output_path = os.path.join(temp_dir, "output.pdf")
            with open(input_path, "wb") as f:
                f.write(self.file_bytes)
            try:
                ocrmypdf.ocr(
                    input_path, output_path, language=language,
                    force_ocr=True, deskew=True, progress_bar=False
                )
                with open(output_path, "rb") as f:
                    self.file_bytes = f.read()
                self.doc.close()
                self.doc = fitz.open(stream=self.file_bytes, filetype="pdf")
                return True
            except Exception as e:
                st.error(f"OCRå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                return False

    def get_existing_toc(self) -> List[ChapterInfo]:
        toc = self.doc.get_toc()
        chapters = []
        if toc:
            for item in toc:
                lvl, title, page = item
                if page > 0:
                    chapters.append(ChapterInfo(title=title, page_num=page, level=lvl, source="æ—¢å­˜ç›®æ¬¡"))
        return chapters

    def _get_page_body_size(self, page) -> float | None:
        """ãƒšãƒ¼ã‚¸å†…ã®æœ¬æ–‡ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºï¼ˆæœ€é »å‡ºï¼‰ã‚’è¿”ã™ã€‚"""
        font_counts = {}
        try:
            for b in page.get_text("dict").get("blocks", []):
                for line in b.get("lines", []):
                    for s in line.get("spans", []):
                        sz = round(s.get("size", 0), 1)
                        if sz > 0:
                            text_len = len((s.get("text") or "").strip())
                            font_counts[sz] = font_counts.get(sz, 0) + text_len
        except Exception:
            return None
        if not font_counts:
            return None
        return max(font_counts, key=font_counts.get)

    def _get_doc_body_size(self, max_pages: int = 20) -> float | None:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå…¨ä½“ã®æœ¬æ–‡ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºï¼ˆæœ€é »å‡ºï¼‰ã‚’è¿”ã™ã€‚"""
        font_counts = {}
        for pi in range(min(max_pages, len(self.doc))):
            try:
                bs = self._get_page_body_size(self.doc[pi])
                if bs is not None:
                    font_counts[bs] = font_counts.get(bs, 0) + 1
            except Exception:
                continue
        return max(font_counts, key=font_counts.get) if font_counts else None

    def detect_chapters_by_style(
        self,
        header_scale: float = 1.3,
        min_page_gap: int = 2,
        top_ratio: float = 0.5,
        per_page_font: bool = True,
    ) -> List[ChapterInfo]:
        """
        ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºè§£æã§è¦‹å‡ºã—ã‚’æ¤œå‡ºã€‚
        per_page_font=True ã®ã¨ãã€å„ãƒšãƒ¼ã‚¸ã”ã¨ã«æœ¬æ–‡ã‚µã‚¤ã‚ºã‚’æ¨å®šã—ã€
        ãã®ãƒšãƒ¼ã‚¸å†…ã§ã€Œæœ¬æ–‡ã‚ˆã‚Šå¤§ãã„ã€ãƒ†ã‚­ã‚¹ãƒˆã ã‘ã‚’è¦‹å‡ºã—å€™è£œã«ã™ã‚‹ï¼ˆãƒ­ãƒã‚¹ãƒˆæ€§å‘ä¸Šï¼‰ã€‚
        """
        fallback_body = self._get_doc_body_size()
        if not per_page_font and fallback_body is None:
            return []

        candidates = []
        for page_index in range(len(self.doc)):
            page = self.doc[page_index]
            page_no = page_index + 1
            page_height = page.rect.height

            if candidates and (page_no - candidates[-1].page_num) < min_page_gap:
                continue

            body_size = self._get_page_body_size(page) if per_page_font else fallback_body
            if body_size is None:
                body_size = fallback_body
            if body_size is None:
                continue

            min_header_size = body_size * header_scale
            blocks = page.get_text("dict").get("blocks", [])
            page_candidates = []
            for b in blocks:
                if "lines" not in b:
                    continue
                for line in b["lines"]:
                    line_top = line.get("bbox", [0, 0, 0, 0])[1]
                    if line_top > page_height * top_ratio:
                        continue
                    for s in line.get("spans", []):
                        text = (s.get("text") or "").strip()
                        if 1 < len(text) < 60 and s.get("size", 0) >= min_header_size:
                            page_candidates.append(text)
            if page_candidates:
                title = " ".join(page_candidates[:1])
                candidates.append(ChapterInfo(title=title, page_num=page_no, level=1, source="è‡ªå‹•æ¤œå‡º"))
        return candidates

    def detect_chapters_by_pattern(
        self,
        min_page_gap: int = 2,
        top_ratio: float = 0.45,
        margin_ratio: float = 0.12,
        min_size_ratio: float = 0.0,
    ) -> List[ChapterInfo]:
        """
        OCRå¾Œã®PDFå‘ã‘: ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒã™ã‚‹è¡Œã‚’ç« ã¨ã—ã¦æ¤œå‡ºã€‚
        - top_ratio: ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ï¼ˆé«˜ã•ã® top_ratio ä»¥å†…ï¼‰ã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿å¯¾è±¡ï¼ˆãƒ•ãƒƒã‚¿ãƒ¼é™¤å¤–ï¼‰
        - margin_ratio: å·¦å³ãƒãƒ¼ã‚¸ãƒ³ï¼ˆå¹…ã® margin_ratio ãšã¤ï¼‰ã‚’é™¤å¤–ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã€Œç¬¬â—‹ç« ã€ã®èª¤æ¤œå‡ºã‚’é˜²ãã€‚
        - min_size_ratio: æœ¬æ–‡ãƒ•ã‚©ãƒ³ãƒˆã«å¯¾ã™ã‚‹æœ€å°å€ç‡ï¼ˆ0=ç„¡åŠ¹ï¼‰ã€‚0.85ä»¥ä¸Šã§ãƒ•ãƒƒã‚¿ãƒ¼ã®å°æ–‡å­—ã‚’é™¤å¤–å¯èƒ½ã€‚
        """
        body_size = None
        if min_size_ratio > 0:
            font_counts = {}
            for pi in range(min(20, len(self.doc))):
                try:
                    for b in self.doc[pi].get_text("dict").get("blocks", []):
                        for line in b.get("lines", []):
                            for s in line.get("spans", []):
                                sz = round(s.get("size", 0), 1)
                                if sz > 0:
                                    font_counts[sz] = font_counts.get(sz, 0) + len((s.get("text") or "").strip())
                except Exception:
                    continue
            if font_counts:
                body_size = max(font_counts, key=font_counts.get)

        candidates = []
        for page_index in range(len(self.doc)):
            page = self.doc[page_index]
            page_no = page_index + 1
            page_height = page.rect.height
            page_width = page.rect.width

            if candidates and (page_no - candidates[-1].page_num) < min_page_gap:
                continue

            blocks = page.get_text("dict").get("blocks", [])
            page_matched = False
            for b in blocks:
                if "lines" not in b or page_matched:
                    continue
                for line in b["lines"]:
                    if page_matched:
                        break
                    line_bbox = line.get("bbox", [0, 0, 0, 0])
                    # ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã®ã¿å¯¾è±¡ï¼ˆãƒ•ãƒƒã‚¿ãƒ¼ã®ã€Œç¬¬â—‹ç« ã€ã‚’é™¤å¤–ï¼‰
                    if line_bbox[1] > page_height * top_ratio:
                        continue
                    # å·¦å³ãƒãƒ¼ã‚¸ãƒ³ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã€Œç¬¬â—‹ç« ã€ãªã©ï¼‰ã‚’é™¤å¤–
                    center_x = (line_bbox[0] + line_bbox[2]) / 2
                    if center_x < page_width * margin_ratio or center_x > page_width * (1 - margin_ratio):
                        continue
                    for span in line.get("spans", []):
                        text = (span.get("text") or "").strip()
                        if not text or len(text) > 80:
                            continue
                        # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã§ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæœ¬æ–‡ã‚ˆã‚Šå°ã•ã„=ãƒ•ãƒƒã‚¿ãƒ¼ã®å¯èƒ½æ€§ï¼‰
                        if body_size and min_size_ratio > 0:
                            sz = span.get("size", 0)
                            if sz < body_size * min_size_ratio:
                                continue
                        for pat in CHAPTER_TITLE_REGEXES:
                            if pat.search(text):
                                candidates.append(
                                    ChapterInfo(
                                        title=text[:60],
                                        page_num=page_no,
                                        level=1,
                                        source="ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º(OCR)",
                                    )
                                )
                                page_matched = True
                                break
        return candidates

    def detect_chapters_from_toc_pages(
        self,
        toc_max_pages: int = 25,
    ) -> List[ChapterInfo]:
        """
        ç›®æ¬¡ãƒšãƒ¼ã‚¸ã‚’ç‰¹å®šã—ã€ç« ã‚¿ã‚¤ãƒˆãƒ«ã¨é–‹å§‹ãƒšãƒ¼ã‚¸ã‚’æŠ½å‡ºã™ã‚‹ã€‚
        ç›®æ¬¡ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯æ›¸ç±ã«ã‚ˆã‚Šç•°ãªã‚‹ãŒã€ã€Œç¬¬1ç«  ... 15ã€ã®ã‚ˆã†ã«
        è¡Œæœ«ã«ãƒšãƒ¼ã‚¸ç•ªå·ãŒã‚ã‚‹å½¢å¼ã‚’æƒ³å®šã™ã‚‹ã€‚
        """
        toc_page_indices = []
        for pi in range(min(toc_max_pages, len(self.doc))):
            try:
                text = self.doc[pi].get_text()
                if not text:
                    continue
                # ã€Œç›®æ¬¡ã€ã€ŒContentsã€ãªã©ãŒå«ã¾ã‚Œã‚‹ãƒšãƒ¼ã‚¸ã‚’å€™è£œã«
                if any(kw in text for kw in ("ç›®æ¬¡", "Contents", "CONTENTS", "Table of Contents")):
                    toc_page_indices.append(pi)
            except Exception:
                continue

        if not toc_page_indices:
            return []

        chapters = []
        seen_pages = set()
        for pi in toc_page_indices:
            try:
                blocks = self.doc[pi].get_text("dict").get("blocks", [])
            except Exception:
                continue
            for b in blocks:
                for line in b.get("lines", []):
                    line_text = " ".join(s.get("text", "") for s in line.get("spans", []))
                    line_text = line_text.strip()
                    if not line_text or len(line_text) > 120:
                        continue
                    # ç›®æ¬¡è¡Œã¨ã—ã¦æœ‰åŠ¹ã‹ï¼ˆç« ãƒ‘ã‚¿ãƒ¼ãƒ³ or ã€Œ1. ã¯ã˜ã‚ã«ã€å½¢å¼ï¼‰
                    if not any(pat.search(line_text) for pat in TOC_ENTRY_PATTERNS):
                        continue
                    # è¡Œæœ«ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’æŠ½å‡ºï¼ˆ.... 15, â€¦â€¦â€¦ 15, 15 ãªã©è¤‡æ•°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
                    page_match = re.search(r"[\s.\ãƒ»â€¦ï¼\-ãƒ¼]*(\d{1,4})\s*$", line_text)
                    if not page_match:
                        continue
                    page_num = int(page_match.group(1))
                    if page_num < 1 or page_num > len(self.doc):
                        continue
                    if page_num in seen_pages:
                        continue
                    seen_pages.add(page_num)
                    title = re.sub(r"[\s.\ãƒ»â€¦ï¼\-ãƒ¼]*\d{1,4}\s*$", "", line_text).strip()
                    if not title:
                        title = line_text[:50]
                    chapters.append(
                        ChapterInfo(
                            title=title[:60],
                            page_num=page_num,
                            level=1,
                            source="ç›®æ¬¡",
                        )
                    )
        return sorted(chapters, key=lambda c: c.page_num)

    def filter_major_chapters(
        self,
        chapters: List[ChapterInfo],
        selected_pattern_ids: List[str] | None = None,
        keyword: str | None = None,
        min_distance: int = 5,
    ) -> List[ChapterInfo]:
        """
        ç« ã ã‘ã‚’æ®‹ã™ãŸã‚ã®ãƒ•ã‚£ãƒ«ã‚¿:
        - ã‚¿ã‚¤ãƒˆãƒ«ãŒç« ã‚¿ã‚¤ãƒˆãƒ«ã‚‰ã—ã„ã‚‚ã®ã ã‘ã‚’æ®‹ã™
          ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã¾ãŸã¯ CHAPTER_TITLE_REGEXES ã«ãƒãƒƒãƒï¼‰
        - åŒã˜ã‚¿ã‚¤ãƒˆãƒ«ãŒè¿‘ã„ãƒšãƒ¼ã‚¸ã«ç¹°ã‚Šè¿”ã—å‡ºã‚‹å ´åˆã¯ã€æœ€åˆã®1ã¤ã ã‘æ®‹ã™
        """
        if not chapters:
            return []

        filtered: List[ChapterInfo] = []
        seen_pages_by_title = {}

        # ã©ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ã†ã‹æ±ºå®šï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§æœªé¸æŠãªã‚‰å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        if selected_pattern_ids:
            active_patterns = []
            for g in CHAPTER_PATTERN_GROUPS:
                if g["id"] in selected_pattern_ids:
                    active_patterns.extend(g["patterns"])
        else:
            active_patterns = CHAPTER_TITLE_REGEXES

        for ch in sorted(chapters, key=lambda c: c.page_num):
            title = (ch.title or "").strip()
            if not title:
                continue

            looks_like_chapter = False
            if keyword and keyword in title:
                looks_like_chapter = True
            else:
                for pat in active_patterns:
                    if pat.search(title):
                        looks_like_chapter = True
                        break

            if not looks_like_chapter:
                continue

            norm_title = re.sub(r"\s+", "", title)
            last_page = seen_pages_by_title.get(norm_title)
            if last_page is not None and (ch.page_num - last_page) < min_distance:
                continue

            seen_pages_by_title[norm_title] = ch.page_num
            filtered.append(ch)

        return filtered

    def process_export(
        self,
        chapters: List[ChapterInfo],
        export_mode: str,
        img_zoom: float = 2.0,
        output_base_dir: str | Path | None = None,
    ) -> tuple[bytes, list[str]]:
        """
        ZIPå½¢å¼ã§å‡ºåŠ›ã€‚export_mode=="image" ã‹ã¤ output_base_dir ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€
        æŒ‡å®šãƒ•ã‚©ãƒ«ãƒ€ã«ã‚‚ä¿å­˜ã™ã‚‹ã€‚
        æˆ»ã‚Šå€¤: (zip_bytes, saved_folder_paths)
        """
        zip_buffer = io.BytesIO()
        sorted_chapters = sorted(chapters, key=lambda x: x.page_num)
        path_stack = []
        saved_folders: list[str] = []

        base_path = Path(output_base_dir).resolve() if output_base_dir else None
        safe_book_title = "".join(
            c for c in self.book_title if c.isalnum() or c in (" ", "-", "_", ".", "(", ")")
        ).strip() or "book"
        book_folder = base_path / safe_book_title if base_path else None
        if book_folder:
            book_folder.mkdir(parents=True, exist_ok=True)

        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
            for i, chapter in enumerate(sorted_chapters):
                start_page = chapter.page_num - 1
                if i == len(sorted_chapters) - 1:
                    end_page = len(self.doc)
                else:
                    end_page = sorted_chapters[i + 1].page_num - 1
                if start_page >= end_page:
                    continue

                while path_stack and path_stack[-1][0] >= chapter.level:
                    path_stack.pop()
                safe_title = "".join(
                    c for c in chapter.title if c.isalnum() or c in (" ", "-", "_", ".", "(", ")")
                ).strip()
                if not safe_title:
                    safe_title = f"Chapter_{i+1}"
                path_stack.append((chapter.level, safe_title))
                folder_parts = [self.book_title] + [p[1] for p in path_stack]

                if export_mode == "pdf":
                    filename = f"{path_stack[-1][1]}.pdf"
                    parent_folder_parts = [self.book_title] + [p[1] for p in path_stack[:-1]]
                    full_path = f"{'/'.join(parent_folder_parts)}/{filename}"
                    new_doc = fitz.open()
                    new_doc.insert_pdf(self.doc, from_page=start_page, to_page=end_page - 1)
                    zf.writestr(full_path, new_doc.tobytes())
                    new_doc.close()

                elif export_mode == "image":
                    current_folder = "/".join(folder_parts)
                    chapter_folder_disk = None
                    if book_folder:
                        chapter_folder_disk = book_folder / safe_title
                        chapter_folder_disk.mkdir(parents=True, exist_ok=True)
                        saved_folders.append(str(chapter_folder_disk))

                    for p_idx in range(start_page, end_page):
                        page = self.doc[p_idx]
                        mat = fitz.Matrix(img_zoom, img_zoom)
                        pix = page.get_pixmap(matrix=mat)
                        img_data = pix.tobytes("jpg")
                        local_num = p_idx - start_page + 1
                        img_name = f"{local_num:03d}.jpg"
                        zf.writestr(f"{current_folder}/{img_name}", img_data)

                        if chapter_folder_disk:
                            (chapter_folder_disk / img_name).write_bytes(img_data)

        zip_buffer.seek(0)
        return zip_buffer.getvalue(), saved_folders


# --- Streamlit UI ---
st.set_page_config(page_title="PDF Structure Master", layout="wide", page_icon="ğŸ“š")
st.title("ğŸ“š PDF Structure Master")
st.markdown("PDFã‚’è§£æã—ã€**ç« ã”ã¨ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ **ã«å†æ§‹ç¯‰ã—ã¾ã™ã€‚ã€Œåˆ†å‰²PDFã€ã¾ãŸã¯ã€Œé€£ç•ªç”»åƒï¼ˆè‡ªç‚Šç”¨ï¼‰ã€ã¨ã—ã¦å‡ºåŠ›å¯èƒ½ã§ã™ã€‚")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®šãƒ»æ“ä½œ")
    st.subheader("1. OCR (æ–‡å­—èªè­˜)")
    if OCR_AVAILABLE:
        ocr_btn = st.button("ğŸ” OCRã‚’å®Ÿè¡Œ (ã‚¹ã‚­ãƒ£ãƒ³ç”»åƒç”¨)")
    else:
        st.warning("âš ï¸ TesseractãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚OCRæ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ã€‚")
        ocr_btn = False
    st.divider()
    st.subheader("2. å‡ºåŠ›ãƒ¢ãƒ¼ãƒ‰")
    export_mode_radio = st.radio("å½¢å¼ã‚’é¸æŠ:", ["PDFã¨ã—ã¦åˆ†å‰²", "ç”»åƒ(JPEG)ãƒ•ã‚©ãƒ«ãƒ€åŒ–"], index=1)
    img_zoom = 2.0
    if export_mode_radio == "ç”»åƒ(JPEG)ãƒ•ã‚©ãƒ«ãƒ€åŒ–":
        quality = st.select_slider("ç”»è³ª (è§£åƒåº¦)", options=["æ¨™æº–", "é«˜ç”»è³ª", "è¶…é«˜ç”»è³ª"], value="é«˜ç”»è³ª")
        if quality == "æ¨™æº–":
            img_zoom = 1.0
        elif quality == "é«˜ç”»è³ª":
            img_zoom = 2.0
        else:
            img_zoom = 3.0

    st.subheader("3. ç« æ¤œå‡ºã®ãã‚ç´°ã‹ã• (ç›®æ¬¡ãªã—ç”¨)")
    sensitivity = st.select_slider(
        "è‡ªå‹•æ¤œå‡ºã®ç²’åº¦",
        options=["ç´°ã‹ã„", "æ¨™æº–", "ç²—ã„"],
        value="æ¨™æº–",
        help="PDFã«åŸ‹ã‚è¾¼ã¿ç›®æ¬¡ãŒãªã„å ´åˆã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ã€ç²—ã„ã€ã»ã©å°‘ãªã„ç« ã«ã¾ã¨ã¾ã‚Šã¾ã™ã€‚",
    )
    header_scale = 1.3
    min_page_gap = 2
    if sensitivity == "ç´°ã‹ã„":
        header_scale = 1.1
        min_page_gap = 1
    elif sensitivity == "æ¨™æº–":
        header_scale = 1.3
        min_page_gap = 3
    else:
        header_scale = 1.5
        min_page_gap = 5
    st.session_state.header_scale = header_scale
    st.session_state.min_page_gap = min_page_gap

    st.subheader("4. ç”»åƒã®ä¿å­˜å…ˆãƒ•ã‚©ãƒ«ãƒ€")
    default_output_dir = r"C:\Users\20171\Learning\PDF_PICTURE"
    output_base_dir = st.text_input(
        "ä¿å­˜å…ˆï¼ˆæœ¬ãƒ•ã‚©ãƒ«ãƒ€ãƒ»ç« ãƒ•ã‚©ãƒ«ãƒ€ãŒã“ã“ã«ä½œæˆã•ã‚Œã¾ã™ï¼‰",
        value=default_output_dir,
        help="åŒä¸€ã‚¿ã‚¤ãƒˆãƒ«ã®æœ¬ãŒãªã‘ã‚Œã°æœ¬ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—ã€åˆ†å‰²ã•ã‚ŒãŸPDFã®ç”»åƒã‚’ç« ãƒ•ã‚©ãƒ«ãƒ€ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚",
    )

    st.subheader("5. ç« ã‚¿ã‚¤ãƒˆãƒ«åˆ¤å®šãƒ«ãƒ¼ãƒ«")
    chapter_pattern_ids = [g["id"] for g in CHAPTER_PATTERN_GROUPS]
    if "chapter_pattern_selected" not in st.session_state:
        st.session_state.chapter_pattern_selected = chapter_pattern_ids
    if "chapter_pattern_manual" not in st.session_state:
        st.session_state.chapter_pattern_manual = False

    selected_ids = st.multiselect(
        "ç« ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦æ‰±ã†ãƒ‘ã‚¿ãƒ¼ãƒ³",
        options=chapter_pattern_ids,
        default=st.session_state.chapter_pattern_selected,
        format_func=lambda id_: next(g["label"] for g in CHAPTER_PATTERN_GROUPS if g["id"] == id_),
        help="æœ¬ã®è¨€èªã‚„æ§‹æˆã«åˆã‚ã›ã¦ã€ç« ã‚¿ã‚¤ãƒˆãƒ«ã¨ã—ã¦ä½¿ã‚ã‚Œãã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã ã‘ã‚’æœ‰åŠ¹ã«ã§ãã¾ã™ã€‚",
        key="chapter_pattern_rules",
    )
    if set(selected_ids) != set(st.session_state.chapter_pattern_selected):
        st.session_state.chapter_pattern_selected = selected_ids
        st.session_state.chapter_pattern_manual = True

if 'processor' not in st.session_state:
    st.session_state.processor = None
if 'chapters' not in st.session_state:
    st.session_state.chapters = []
if 'ocr_done' not in st.session_state:
    st.session_state.ocr_done = False

uploaded_file = st.file_uploader("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã“ã«ãƒ‰ãƒ©ãƒƒã‚°ï¼†ãƒ‰ãƒ­ãƒƒãƒ—", type=["pdf"])

if uploaded_file is not None:
    if st.session_state.processor is None or getattr(st.session_state, 'last_filename', '') != uploaded_file.name:
        with st.spinner("PDFã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™..."):
            st.session_state.processor = PDFProcessor(uploaded_file, uploaded_file.name)
            st.session_state.last_filename = uploaded_file.name
            st.session_state.chapters = []
            st.session_state.ocr_done = False
            st.session_state.chapters = st.session_state.processor.get_existing_toc()
            if not st.session_state.chapters:
                st.session_state.chapters = st.session_state.processor.detect_chapters_from_toc_pages()
            if not st.session_state.chapters:
                header_scale = st.session_state.get("header_scale", 1.3)
                min_page_gap = st.session_state.get("min_page_gap", 2)
                st.session_state.chapters = st.session_state.processor.detect_chapters_by_style(
                    header_scale, min_page_gap
                )
            if not st.session_state.chapters:
                min_page_gap = st.session_state.get("min_page_gap", 2)
                st.session_state.chapters = st.session_state.processor.detect_chapters_by_pattern(
                    min_page_gap, top_ratio=0.45, min_size_ratio=0.85
                )
            # ã¾ã ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ˜ç¤ºçš„ã«å¤‰æ›´ã—ã¦ã„ãªã„å ´åˆã¯ã€æ¤œå‡ºã•ã‚ŒãŸè¦‹å‡ºã—ã‹ã‚‰
            # ç« ã‚¿ã‚¤ãƒˆãƒ«åˆ¤å®šãƒ«ãƒ¼ãƒ«ã®ãŠã™ã™ã‚ã‚»ãƒƒãƒˆã‚’è‡ªå‹•ã§æ¨å®šã™ã‚‹
            if not st.session_state.get("chapter_pattern_manual", False):
                st.session_state.chapter_pattern_selected = suggest_chapter_pattern_ids(
                    st.session_state.chapters
                )

    processor = st.session_state.processor

    if ocr_btn and not st.session_state.ocr_done:
        with st.spinner("OCRå‡¦ç†ä¸­... ãƒšãƒ¼ã‚¸æ•°ã«ã‚ˆã£ã¦ã¯æ•°åˆ†ã‹ã‹ã‚Šã¾ã™â˜•"):
            if processor.run_ocr():
                st.session_state.ocr_done = True
                header_scale = st.session_state.get("header_scale", 1.3)
                min_page_gap = st.session_state.get("min_page_gap", 2)
                st.session_state.chapters = processor.detect_chapters_by_style(header_scale, min_page_gap)
                if not st.session_state.chapters:
                    st.session_state.chapters = processor.detect_chapters_from_toc_pages()
                if not st.session_state.chapters:
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºï¼ˆãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã®ã¿ãƒ»ãƒ•ãƒƒã‚¿ãƒ¼é™¤å¤–ãƒ»æœ¬æ–‡85%ä»¥ä¸Šï¼‰
                    st.session_state.chapters = processor.detect_chapters_by_pattern(
                        min_page_gap, top_ratio=0.45, min_size_ratio=0.85
                    )
                if not st.session_state.get("chapter_pattern_manual", False):
                    st.session_state.chapter_pattern_selected = suggest_chapter_pattern_ids(
                        st.session_state.chapters
                    )
                st.session_state.ocr_complete_toast = True
                notify_ocr_complete()
                st.success("OCRå®Œäº†ï¼ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
                st.rerun()

    if not st.session_state.chapters:
        st.error("ç« ã®åŒºåˆ‡ã‚ŠãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚OCRã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        col_toc, col_pat = st.columns(2)
        with col_toc:
            if st.button("ğŸ“‘ ç›®æ¬¡ãƒšãƒ¼ã‚¸ã‹ã‚‰æ¤œå‡º"):
                st.session_state.chapters = processor.detect_chapters_from_toc_pages()
                if st.session_state.chapters:
                    st.session_state.chapter_pattern_selected = suggest_chapter_pattern_ids(
                        st.session_state.chapters
                    )
                    st.success(f"{len(st.session_state.chapters)}ä»¶ã®ç« ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
                    st.rerun()
                else:
                    st.warning("ç›®æ¬¡ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        with col_pat:
            if st.button("ğŸ” ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã‚’è©¦ã™ï¼ˆãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã®ã¿ï¼‰"):
                min_page_gap = st.session_state.get("min_page_gap", 2)
                st.session_state.chapters = processor.detect_chapters_by_pattern(
                    min_page_gap, top_ratio=0.45, min_size_ratio=0.85
                )
                if st.session_state.chapters:
                    st.session_state.chapter_pattern_selected = suggest_chapter_pattern_ids(
                        st.session_state.chapters
                    )
                    st.success(f"{len(st.session_state.chapters)}ä»¶ã®ç« ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
                    st.rerun()
                else:
                    st.warning("ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã™ã‚‹è¦‹å‡ºã—ã‚‚è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        if st.session_state.pop("ocr_complete_toast", False):
            st.toast("OCRãŒå®Œäº†ã—ã¾ã—ãŸ", icon="âœ…")
        st.subheader("ğŸ›  ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã®ç·¨é›†")
        st.caption("ã€éšå±¤(Lv)ã€ã‚’èª¿æ•´ã™ã‚‹ã¨ã€ãƒ•ã‚©ãƒ«ãƒ€ã®å…¥ã‚Œå­æ§‹é€ ã‚’ä½œæˆã§ãã¾ã™ (Lv1=è¦ªãƒ•ã‚©ãƒ«ãƒ€, Lv2=ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€...)ã€‚")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ” è¦‹å‡ºã—è‡ªå‹•æ¤œå‡ºã‚’ã‚„ã‚Šç›´ã™"):
                header_scale = st.session_state.get("header_scale", 1.3)
                min_page_gap = st.session_state.get("min_page_gap", 2)
                st.session_state.chapters = processor.detect_chapters_by_style(header_scale, min_page_gap)
                if not st.session_state.chapters:
                    st.session_state.chapters = processor.detect_chapters_from_toc_pages()
                if not st.session_state.chapters:
                    st.session_state.chapters = processor.detect_chapters_by_pattern(
                        min_page_gap, top_ratio=0.45, min_size_ratio=0.85
                    )
                if not st.session_state.get("chapter_pattern_manual", False):
                    st.session_state.chapter_pattern_selected = suggest_chapter_pattern_ids(
                        st.session_state.chapters
                    )
                st.success("è¦‹å‡ºã—ã‚’å†æ¤œå‡ºã—ã¾ã—ãŸã€‚" if st.session_state.chapters else "è¦‹å‡ºã—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                st.rerun()
        with col2:
            if st.button("ğŸ“‘ ã€ç« ã€ã ã‘ã«è‡ªå‹•æ•´ç†ï¼ˆé‡è¤‡é™¤å»ï¼‰"):
                selected_ids = st.session_state.get("chapter_pattern_selected")
                filtered = processor.filter_major_chapters(
                    st.session_state.chapters,
                    selected_pattern_ids=selected_ids,
                    keyword=None,
                    min_distance=5,
                )
                if not filtered:
                    st.warning("ç« ãƒ¬ãƒ™ãƒ«ã®è¦‹å‡ºã—ãŒè‡ªå‹•ã§ã¯åˆ¤å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
                else:
                    st.session_state.chapters = filtered
                    st.success(f"{len(filtered)}ä»¶ã®ç« ãƒ¬ãƒ™ãƒ«è¦‹å‡ºã—ã«çµã‚Šè¾¼ã¿ã¾ã—ãŸã€‚")
                    st.rerun()
        df_data = [
            {"Selected": c.selected, "Level": c.level, "Page": c.page_num, "Title": c.title, "Source": c.source}
            for c in st.session_state.chapters
        ]
        edited_df = st.data_editor(
            df_data,
            column_config={
                "Selected": st.column_config.CheckboxColumn("å‡ºåŠ›", width="small"),
                "Level": st.column_config.NumberColumn("éšå±¤ Lv", min_value=1, max_value=5, width="small"),
                "Page": st.column_config.NumberColumn("é–‹å§‹P", width="small"),
                "Title": st.column_config.TextColumn("ãƒ•ã‚©ãƒ«ãƒ€/ãƒ•ã‚¡ã‚¤ãƒ«å", width="large"),
                "Source": st.column_config.TextColumn("æ¤œå‡ºå…ƒ", disabled=True, width="small"),
            },
            width="stretch",
            num_rows="dynamic",
            height=400,
        )

        export_label = "ç”»åƒã«å¤‰æ›ã—ã¦ä¿å­˜" if export_mode_radio == "ç”»åƒ(JPEG)ãƒ•ã‚©ãƒ«ãƒ€åŒ–" else "åˆ†å‰²PDFã‚’ä¿å­˜"
        if st.button(f"ğŸš€ {export_label}", type="primary"):
            final_chapters = []
            for row in edited_df:
                if row["Selected"]:
                    final_chapters.append(ChapterInfo(
                        title=str(row["Title"]),
                        page_num=int(row["Page"]),
                        level=int(row["Level"]),
                        source="User"
                    ))
            if not final_chapters:
                st.warning("å‡ºåŠ›å¯¾è±¡ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            else:
                mode_str = "image" if export_mode_radio == "ç”»åƒ(JPEG)ãƒ•ã‚©ãƒ«ãƒ€åŒ–" else "pdf"
                out_dir = output_base_dir.strip() if mode_str == "image" else None
                with st.spinner("å‡¦ç†ä¸­... ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆã—æ›¸ãå‡ºã—ã¦ã„ã¾ã™..."):
                    try:
                        zip_bytes, saved_folders = processor.process_export(
                            final_chapters, mode_str, img_zoom,
                            output_base_dir=out_dir if out_dir else None,
                        )
                        dl_name = f"{processor.book_title}_{mode_str}.zip"
                        st.balloons()
                        if saved_folders:
                            book_path = Path(saved_folders[0]).parent if saved_folders else Path(output_base_dir)
                            st.success(
                                f"ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã—ã¾ã—ãŸ: **{book_path}** ï¼ˆç« ãƒ•ã‚©ãƒ«ãƒ€: {len(saved_folders)} ä»¶ï¼‰"
                            )
                        st.download_button(
                            label=f"ğŸ“¦ ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ({dl_name})",
                            data=zip_bytes,
                            file_name=dl_name,
                            mime="application/zip",
                        )
                    except Exception as e:
                        st.error(f"æ›¸ãå‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
